{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9330e74f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T21:32:43.972157Z",
     "iopub.status.busy": "2025-05-06T21:32:43.971810Z",
     "iopub.status.idle": "2025-05-06T21:33:58.192932Z",
     "shell.execute_reply": "2025-05-06T21:33:58.192234Z"
    },
    "papermill": {
     "duration": 74.228825,
     "end_time": "2025-05-06T21:33:58.194480",
     "exception": false,
     "start_time": "2025-05-06T21:32:43.965655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\r\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\r\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.5)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\r\n",
      "Requirement already satisfied: torchsummary in /usr/local/lib/python3.11/dist-packages (1.5.1)\r\n",
      "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.11)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub) (6.0.2)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub) (4.67.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2025.1.31)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\r\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.90\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision opencv-python numpy pandas matplotlib scikit-learn torchsummary kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "555617d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T21:33:58.237118Z",
     "iopub.status.busy": "2025-05-06T21:33:58.236862Z",
     "iopub.status.idle": "2025-05-06T22:18:54.579339Z",
     "shell.execute_reply": "2025-05-06T22:18:54.578324Z"
    },
    "papermill": {
     "duration": 2696.365724,
     "end_time": "2025-05-06T22:18:54.580730",
     "exception": true,
     "start_time": "2025-05-06T21:33:58.215006",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Training configuration:\n",
      "  batch_size: 16\n",
      "  num_epochs: 15\n",
      "  base_lr: 0.0005\n",
      "  weight_decay: 2e-05\n",
      "  scheduler: onecycle\n",
      "  mixup_alpha: 0.2\n",
      "  label_smoothing: 0.1\n",
      "  dropout_rate: 0.4\n",
      "  model_variant: efficient_cbam\n",
      "  num_classes: 3\n",
      "Downloading dataset...\n",
      "Path to dataset files: /kaggle/input/figshare-brain-tumor-dataset\n",
      "\n",
      "==================== RUNNING FOLD 1 ====================\n",
      "\n",
      "Found 3064 .mat files\n",
      "Processed 0 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/1625073196.py:93: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  lbl.append(int(images['label'][0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 500 images\n",
      "Processed 1000 images\n",
      "Processed 1500 images\n",
      "Processed 2000 images\n",
      "Processed 2500 images\n",
      "Processed 3000 images\n",
      "Found cvind.mat at: /kaggle/input/figshare-brain-tumor-dataset/dataset/cvind.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b4_rwightman-23ab8bcd.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b4_rwightman-23ab8bcd.pth\n",
      "100%|██████████| 74.5M/74.5M [00:00<00:00, 160MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "----------\n",
      "Train Loss: 0.8517 Acc: 0.6525\n",
      "Val Loss: 0.5621 Acc: 0.8376\n",
      "New best model saved with accuracy: 0.8376\n",
      "\n",
      "Epoch 2/15\n",
      "----------\n",
      "Train Loss: 0.7223 Acc: 0.7543\n",
      "Val Loss: 0.4923 Acc: 0.9096\n",
      "New best model saved with accuracy: 0.9096\n",
      "\n",
      "Epoch 3/15\n",
      "----------\n",
      "Train Loss: 0.6604 Acc: 0.8039\n",
      "Val Loss: 0.4495 Acc: 0.9207\n",
      "New best model saved with accuracy: 0.9207\n",
      "\n",
      "Epoch 4/15\n",
      "----------\n",
      "Train Loss: 0.6452 Acc: 0.8151\n",
      "Val Loss: 0.4510 Acc: 0.9225\n",
      "New best model saved with accuracy: 0.9225\n",
      "\n",
      "Epoch 5/15\n",
      "----------\n",
      "Train Loss: 0.6355 Acc: 0.8213\n",
      "Val Loss: 0.4247 Acc: 0.9188\n",
      "\n",
      "Epoch 6/15\n",
      "----------\n",
      "Train Loss: 0.5984 Acc: 0.8476\n",
      "Val Loss: 0.4291 Acc: 0.9280\n",
      "New best model saved with accuracy: 0.9280\n",
      "\n",
      "Epoch 7/15\n",
      "----------\n",
      "Train Loss: 0.5937 Acc: 0.8524\n",
      "Val Loss: 0.4028 Acc: 0.9428\n",
      "New best model saved with accuracy: 0.9428\n",
      "\n",
      "Epoch 8/15\n",
      "----------\n",
      "Train Loss: 0.6098 Acc: 0.8381\n",
      "Val Loss: 0.3928 Acc: 0.9483\n",
      "New best model saved with accuracy: 0.9483\n",
      "\n",
      "Epoch 9/15\n",
      "----------\n",
      "Train Loss: 0.5597 Acc: 0.8667\n",
      "Val Loss: 0.4153 Acc: 0.9373\n",
      "\n",
      "Epoch 10/15\n",
      "----------\n",
      "Train Loss: 0.5823 Acc: 0.8645\n",
      "Val Loss: 0.3800 Acc: 0.9631\n",
      "New best model saved with accuracy: 0.9631\n",
      "\n",
      "Epoch 11/15\n",
      "----------\n",
      "Train Loss: 0.5779 Acc: 0.8620\n",
      "Val Loss: 0.3701 Acc: 0.9686\n",
      "New best model saved with accuracy: 0.9686\n",
      "\n",
      "Epoch 12/15\n",
      "----------\n",
      "Train Loss: 0.5466 Acc: 0.8793\n",
      "Val Loss: 0.3797 Acc: 0.9613\n",
      "\n",
      "Epoch 13/15\n",
      "----------\n",
      "Train Loss: 0.5639 Acc: 0.8691\n",
      "Val Loss: 0.3669 Acc: 0.9649\n",
      "\n",
      "Epoch 14/15\n",
      "----------\n",
      "Train Loss: 0.5780 Acc: 0.8601\n",
      "Val Loss: 0.3623 Acc: 0.9705\n",
      "New best model saved with accuracy: 0.9705\n",
      "\n",
      "Epoch 15/15\n",
      "----------\n",
      "Train Loss: 0.5459 Acc: 0.8732\n",
      "Val Loss: 0.3559 Acc: 0.9760\n",
      "New best model saved with accuracy: 0.9760\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/1625073196.py:564: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'best_{CONFIG[\"model_variant\"]}_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 accuracy: 0.9760\n",
      "Training time: 605.66 seconds\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95       113\n",
      "           1       0.99      0.97      0.98       288\n",
      "           2       0.98      0.99      0.99       141\n",
      "\n",
      "    accuracy                           0.98       542\n",
      "   macro avg       0.97      0.98      0.97       542\n",
      "weighted avg       0.98      0.98      0.98       542\n",
      "\n",
      "\n",
      "ROC AUC Scores:\n",
      "Class 0: 0.9946\n",
      "Class 1: 0.9988\n",
      "Class 2: 0.9992\n",
      "Micro-average: 0.9983\n",
      "Macro-average: 0.9980\n",
      "Random image test - True: Meningioma, Predicted: Meningioma\n",
      "Confidence scores: [0.689229  0.2733773 0.0373936]\n",
      "\n",
      "==================== RUNNING FOLD 2 ====================\n",
      "\n",
      "Found 3064 .mat files\n",
      "Processed 0 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/1625073196.py:93: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  lbl.append(int(images['label'][0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 500 images\n",
      "Processed 1000 images\n",
      "Processed 1500 images\n",
      "Processed 2000 images\n",
      "Processed 2500 images\n",
      "Processed 3000 images\n",
      "Found cvind.mat at: /kaggle/input/figshare-brain-tumor-dataset/dataset/cvind.mat\n",
      "Epoch 1/15\n",
      "----------\n",
      "Error in fold 2: Expected more than 1 value per channel when training, got input size torch.Size([1, 512])\n",
      "\n",
      "==================== RUNNING FOLD 3 ====================\n",
      "\n",
      "Found 3064 .mat files\n",
      "Processed 0 images\n",
      "Processed 500 images\n",
      "Processed 1000 images\n",
      "Processed 1500 images\n",
      "Processed 2000 images\n",
      "Processed 2500 images\n",
      "Processed 3000 images\n",
      "Found cvind.mat at: /kaggle/input/figshare-brain-tumor-dataset/dataset/cvind.mat\n",
      "Epoch 1/15\n",
      "----------\n",
      "Train Loss: 0.8465 Acc: 0.6575\n",
      "Val Loss: 0.5583 Acc: 0.8636\n",
      "New best model saved with accuracy: 0.8636\n",
      "\n",
      "Epoch 2/15\n",
      "----------\n",
      "Train Loss: 0.7114 Acc: 0.7641\n",
      "Val Loss: 0.4741 Acc: 0.9178\n",
      "New best model saved with accuracy: 0.9178\n",
      "\n",
      "Epoch 3/15\n",
      "----------\n",
      "Train Loss: 0.6666 Acc: 0.7970\n",
      "Val Loss: 0.4341 Acc: 0.9563\n",
      "New best model saved with accuracy: 0.9563\n",
      "\n",
      "Epoch 4/15\n",
      "----------\n",
      "Train Loss: 0.6426 Acc: 0.8150\n",
      "Val Loss: 0.4115 Acc: 0.9476\n",
      "\n",
      "Epoch 5/15\n",
      "----------\n",
      "Train Loss: 0.6219 Acc: 0.8227\n",
      "Val Loss: 0.3962 Acc: 0.9598\n",
      "New best model saved with accuracy: 0.9598\n",
      "\n",
      "Epoch 6/15\n",
      "----------\n",
      "Train Loss: 0.6071 Acc: 0.8383\n",
      "Val Loss: 0.3935 Acc: 0.9476\n",
      "\n",
      "Epoch 7/15\n",
      "----------\n",
      "Train Loss: 0.5967 Acc: 0.8429\n",
      "Val Loss: 0.3941 Acc: 0.9580\n",
      "\n",
      "Epoch 8/15\n",
      "----------\n",
      "Train Loss: 0.5642 Acc: 0.8620\n",
      "Val Loss: 0.3934 Acc: 0.9563\n",
      "\n",
      "Epoch 9/15\n",
      "----------\n",
      "Train Loss: 0.5560 Acc: 0.8658\n",
      "Val Loss: 0.3733 Acc: 0.9668\n",
      "New best model saved with accuracy: 0.9668\n",
      "\n",
      "Epoch 10/15\n",
      "----------\n",
      "Train Loss: 0.5522 Acc: 0.8733\n",
      "Val Loss: 0.3704 Acc: 0.9615\n",
      "\n",
      "Epoch 11/15\n",
      "----------\n",
      "Train Loss: 0.5708 Acc: 0.8672\n",
      "Val Loss: 0.3827 Acc: 0.9598\n",
      "\n",
      "Epoch 12/15\n",
      "----------\n",
      "Train Loss: 0.5644 Acc: 0.8725\n",
      "Val Loss: 0.3714 Acc: 0.9668\n",
      "\n",
      "Epoch 13/15\n",
      "----------\n",
      "Train Loss: 0.5494 Acc: 0.8815\n",
      "Val Loss: 0.3748 Acc: 0.9703\n",
      "New best model saved with accuracy: 0.9703\n",
      "\n",
      "Epoch 14/15\n",
      "----------\n",
      "Train Loss: 0.5656 Acc: 0.8673\n",
      "Val Loss: 0.3690 Acc: 0.9650\n",
      "\n",
      "Epoch 15/15\n",
      "----------\n",
      "Train Loss: 0.5478 Acc: 0.8780\n",
      "Val Loss: 0.3736 Acc: 0.9563\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/1625073196.py:564: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'best_{CONFIG[\"model_variant\"]}_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 accuracy: 0.9703\n",
      "Training time: 603.52 seconds\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93        99\n",
      "           1       0.97      0.99      0.98       267\n",
      "           2       1.00      0.96      0.98       206\n",
      "\n",
      "    accuracy                           0.97       572\n",
      "   macro avg       0.96      0.97      0.96       572\n",
      "weighted avg       0.97      0.97      0.97       572\n",
      "\n",
      "\n",
      "ROC AUC Scores:\n",
      "Class 0: 0.9913\n",
      "Class 1: 0.9968\n",
      "Class 2: 0.9992\n",
      "Micro-average: 0.9961\n",
      "Macro-average: 0.9961\n",
      "Random image test - True: Pituitary, Predicted: Pituitary\n",
      "Confidence scores: [0.09842034 0.05244412 0.8491356 ]\n",
      "\n",
      "==================== RUNNING FOLD 4 ====================\n",
      "\n",
      "Found 3064 .mat files\n",
      "Processed 0 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/1625073196.py:93: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  lbl.append(int(images['label'][0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 500 images\n",
      "Processed 1000 images\n",
      "Processed 1500 images\n",
      "Processed 2000 images\n",
      "Processed 2500 images\n",
      "Processed 3000 images\n",
      "Found cvind.mat at: /kaggle/input/figshare-brain-tumor-dataset/dataset/cvind.mat\n",
      "Epoch 1/15\n",
      "----------\n",
      "Train Loss: 0.8498 Acc: 0.6592\n",
      "Val Loss: 0.6058 Acc: 0.8471\n",
      "New best model saved with accuracy: 0.8471\n",
      "\n",
      "Epoch 2/15\n",
      "----------\n",
      "Train Loss: 0.7172 Acc: 0.7647\n",
      "Val Loss: 0.5215 Acc: 0.8917\n",
      "New best model saved with accuracy: 0.8917\n",
      "\n",
      "Epoch 3/15\n",
      "----------\n",
      "Train Loss: 0.6582 Acc: 0.8007\n",
      "Val Loss: 0.4554 Acc: 0.9172\n",
      "New best model saved with accuracy: 0.9172\n",
      "\n",
      "Epoch 4/15\n",
      "----------\n",
      "Train Loss: 0.6155 Acc: 0.8369\n",
      "Val Loss: 0.4402 Acc: 0.9347\n",
      "New best model saved with accuracy: 0.9347\n",
      "\n",
      "Epoch 5/15\n",
      "----------\n",
      "Train Loss: 0.6136 Acc: 0.8385\n",
      "Val Loss: 0.4301 Acc: 0.9315\n",
      "\n",
      "Epoch 6/15\n",
      "----------\n",
      "Train Loss: 0.5994 Acc: 0.8479\n",
      "Val Loss: 0.4160 Acc: 0.9506\n",
      "New best model saved with accuracy: 0.9506\n",
      "\n",
      "Epoch 7/15\n",
      "----------\n",
      "Train Loss: 0.5861 Acc: 0.8580\n",
      "Val Loss: 0.4100 Acc: 0.9347\n",
      "\n",
      "Epoch 8/15\n",
      "----------\n",
      "Train Loss: 0.6003 Acc: 0.8451\n",
      "Val Loss: 0.4311 Acc: 0.9299\n",
      "\n",
      "Epoch 9/15\n",
      "----------\n",
      "Train Loss: 0.5729 Acc: 0.8672\n",
      "Val Loss: 0.3822 Acc: 0.9554\n",
      "New best model saved with accuracy: 0.9554\n",
      "\n",
      "Epoch 10/15\n",
      "----------\n",
      "Train Loss: 0.5379 Acc: 0.8836\n",
      "Val Loss: 0.3771 Acc: 0.9634\n",
      "New best model saved with accuracy: 0.9634\n",
      "\n",
      "Epoch 11/15\n",
      "----------\n",
      "Train Loss: 0.5689 Acc: 0.8696\n",
      "Val Loss: 0.3993 Acc: 0.9554\n",
      "\n",
      "Epoch 12/15\n",
      "----------\n",
      "Train Loss: 0.5617 Acc: 0.8651\n",
      "Val Loss: 0.3765 Acc: 0.9666\n",
      "New best model saved with accuracy: 0.9666\n",
      "\n",
      "Epoch 13/15\n",
      "----------\n",
      "Train Loss: 0.5609 Acc: 0.8730\n",
      "Val Loss: 0.3733 Acc: 0.9618\n",
      "\n",
      "Epoch 14/15\n",
      "----------\n",
      "Train Loss: 0.5645 Acc: 0.8654\n",
      "Val Loss: 0.3805 Acc: 0.9634\n",
      "\n",
      "Epoch 15/15\n",
      "----------\n",
      "Train Loss: 0.5455 Acc: 0.8819\n",
      "Val Loss: 0.3532 Acc: 0.9697\n",
      "New best model saved with accuracy: 0.9697\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/1625073196.py:564: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'best_{CONFIG[\"model_variant\"]}_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 accuracy: 0.9697\n",
      "Training time: 595.53 seconds\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       168\n",
      "           1       0.98      0.98      0.98       287\n",
      "           2       0.96      0.98      0.97       173\n",
      "\n",
      "    accuracy                           0.97       628\n",
      "   macro avg       0.97      0.97      0.97       628\n",
      "weighted avg       0.97      0.97      0.97       628\n",
      "\n",
      "\n",
      "ROC AUC Scores:\n",
      "Class 0: 0.9980\n",
      "Class 1: 0.9990\n",
      "Class 2: 0.9991\n",
      "Micro-average: 0.9987\n",
      "Macro-average: 0.9988\n",
      "Random image test - True: Pituitary, Predicted: Pituitary\n",
      "Confidence scores: [0.06013858 0.03194652 0.9079149 ]\n",
      "\n",
      "==================== RUNNING FOLD 5 ====================\n",
      "\n",
      "Found 3064 .mat files\n",
      "Processed 0 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/1625073196.py:93: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  lbl.append(int(images['label'][0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 500 images\n",
      "Processed 1000 images\n",
      "Processed 1500 images\n",
      "Processed 2000 images\n",
      "Processed 2500 images\n",
      "Processed 3000 images\n",
      "Found cvind.mat at: /kaggle/input/figshare-brain-tumor-dataset/dataset/cvind.mat\n",
      "Epoch 1/15\n",
      "----------\n",
      "Train Loss: 0.8297 Acc: 0.6696\n",
      "Val Loss: 0.5952 Acc: 0.8351\n",
      "New best model saved with accuracy: 0.8351\n",
      "\n",
      "Epoch 2/15\n",
      "----------\n",
      "Train Loss: 0.7125 Acc: 0.7553\n",
      "Val Loss: 0.5240 Acc: 0.8865\n",
      "New best model saved with accuracy: 0.8865\n",
      "\n",
      "Epoch 3/15\n",
      "----------\n",
      "Train Loss: 0.6550 Acc: 0.7986\n",
      "Val Loss: 0.4622 Acc: 0.8927\n",
      "New best model saved with accuracy: 0.8927\n",
      "\n",
      "Epoch 4/15\n",
      "----------\n",
      "Train Loss: 0.6405 Acc: 0.8208\n",
      "Val Loss: 0.4355 Acc: 0.9238\n",
      "New best model saved with accuracy: 0.9238\n",
      "\n",
      "Epoch 5/15\n",
      "----------\n",
      "Train Loss: 0.6215 Acc: 0.8284\n",
      "Val Loss: 0.4365 Acc: 0.9269\n",
      "New best model saved with accuracy: 0.9269\n",
      "\n",
      "Epoch 6/15\n",
      "----------\n",
      "Train Loss: 0.6457 Acc: 0.8231\n",
      "Val Loss: 0.4379 Acc: 0.9362\n",
      "New best model saved with accuracy: 0.9362\n",
      "\n",
      "Epoch 7/15\n",
      "----------\n",
      "Train Loss: 0.6076 Acc: 0.8404\n",
      "Val Loss: 0.4306 Acc: 0.9160\n",
      "\n",
      "Epoch 8/15\n",
      "----------\n",
      "Train Loss: 0.5901 Acc: 0.8583\n",
      "Val Loss: 0.4191 Acc: 0.9425\n",
      "New best model saved with accuracy: 0.9425\n",
      "\n",
      "Epoch 9/15\n",
      "----------\n",
      "Train Loss: 0.5931 Acc: 0.8500\n",
      "Val Loss: 0.4017 Acc: 0.9440\n",
      "New best model saved with accuracy: 0.9440\n",
      "\n",
      "Epoch 10/15\n",
      "----------\n",
      "Train Loss: 0.5986 Acc: 0.8442\n",
      "Val Loss: 0.3977 Acc: 0.9533\n",
      "New best model saved with accuracy: 0.9533\n",
      "\n",
      "Epoch 11/15\n",
      "----------\n",
      "Train Loss: 0.5808 Acc: 0.8582\n",
      "Val Loss: 0.4024 Acc: 0.9425\n",
      "\n",
      "Epoch 12/15\n",
      "----------\n",
      "Train Loss: 0.5682 Acc: 0.8726\n",
      "Val Loss: 0.3950 Acc: 0.9456\n",
      "\n",
      "Epoch 13/15\n",
      "----------\n",
      "Train Loss: 0.5387 Acc: 0.8871\n",
      "Val Loss: 0.3937 Acc: 0.9518\n",
      "\n",
      "Epoch 14/15\n",
      "----------\n",
      "Train Loss: 0.5548 Acc: 0.8715\n",
      "Val Loss: 0.3944 Acc: 0.9440\n",
      "\n",
      "Epoch 15/15\n",
      "----------\n",
      "Train Loss: 0.5440 Acc: 0.8820\n",
      "Val Loss: 0.4065 Acc: 0.9425\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/1625073196.py:564: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'best_{CONFIG[\"model_variant\"]}_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 accuracy: 0.9533\n",
      "Training time: 593.24 seconds\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90       144\n",
      "           1       0.99      0.96      0.97       296\n",
      "           2       0.95      0.99      0.97       203\n",
      "\n",
      "    accuracy                           0.95       643\n",
      "   macro avg       0.94      0.95      0.95       643\n",
      "weighted avg       0.95      0.95      0.95       643\n",
      "\n",
      "\n",
      "ROC AUC Scores:\n",
      "Class 0: 0.9903\n",
      "Class 1: 0.9978\n",
      "Class 2: 0.9971\n",
      "Micro-average: 0.9955\n",
      "Macro-average: 0.9955\n",
      "Random image test - True: Pituitary, Predicted: Pituitary\n",
      "Confidence scores: [0.05183881 0.03130339 0.9168578 ]\n",
      "\n",
      "Average accuracy across all folds: 0.9673\n",
      "Average micro-average AUC: 0.9972\n",
      "Average macro-average AUC: 0.9971\n",
      "\n",
      "Model Configuration Summary:\n",
      "  Model variant: efficient_cbam\n",
      "  Batch size: 16\n",
      "  Epochs: 15\n",
      "  Learning rate: 0.0005\n",
      "  Weight decay: 2e-05\n",
      "  Scheduler: onecycle\n",
      "  MixUp alpha: 0.2\n",
      "  Label smoothing: 0.1\n",
      "  Dropout rate: 0.4\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val_acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19/1625073196.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults_all\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'Fold {fold}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Validation Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_acc'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import kagglehub\n",
    "import glob\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc, classification_report\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, OneCycleLR\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Configuration parameters\n",
    "CONFIG = {\n",
    "    'batch_size': 16,\n",
    "    'num_epochs': 15,  # Increased from 10 to 15\n",
    "    'base_lr': 5e-4,   # Changed from 1e-4\n",
    "    'weight_decay': 2e-5,  # Changed from 1e-4\n",
    "    'scheduler': 'onecycle',  # Options: 'cosine', 'onecycle'\n",
    "    'mixup_alpha': 0.2,  # Added mixup augmentation\n",
    "    'label_smoothing': 0.1,  # Added label smoothing\n",
    "    'dropout_rate': 0.4,  # Increased dropout\n",
    "    'model_variant': 'efficient_cbam',  # Options: 'efficient_basic', 'efficient_cbam', 'efficient_dual'\n",
    "    'num_classes': 3\n",
    "}\n",
    "\n",
    "print(\"Training configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Download the dataset using kagglehub\n",
    "print(\"Downloading dataset...\")\n",
    "dataset_path = kagglehub.dataset_download(\"ashkhagan/figshare-brain-tumor-dataset\")\n",
    "print(\"Path to dataset files:\", dataset_path)\n",
    "\n",
    "# Data loading functions\n",
    "def load_data():\n",
    "    \"\"\"Load and preprocess data from the downloaded directory\"\"\"\n",
    "    # First find all .mat files in the dataset directory and its subdirectories\n",
    "    mat_files = []\n",
    "    for root, dirs, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.mat') and file != 'cvind.mat':\n",
    "                mat_files.append(os.path.join(root, file))\n",
    "   \n",
    "    print(f\"Found {len(mat_files)} .mat files\")\n",
    "   \n",
    "    # If we don't have enough files, exit\n",
    "    if len(mat_files) < 3000:\n",
    "        raise ValueError(f\"Expected ~3064 .mat files but found only {len(mat_files)}\")\n",
    "   \n",
    "    # Sort the files to ensure consistent order\n",
    "    mat_files.sort()\n",
    "   \n",
    "    # Prepare arrays for images and labels\n",
    "    img = np.zeros((len(mat_files), 224, 224))\n",
    "    lbl = []\n",
    "   \n",
    "    # Load each file\n",
    "    for i, file_path in enumerate(mat_files):\n",
    "        try:\n",
    "            with h5py.File(file_path, 'r') as f:\n",
    "                images = f['cjdata']\n",
    "                resized = cv2.resize(images['image'][:,:], (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "                x = np.asarray(resized)\n",
    "                x = (x - np.min(x)) / (np.max(x) - np.min(x))  # Normalization\n",
    "                x = x.reshape((1, 224, 224))\n",
    "                img[i] = x\n",
    "                lbl.append(int(images['label'][0]))\n",
    "               \n",
    "                if i % 500 == 0:\n",
    "                    print(f\"Processed {i} images\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load image at {file_path}: {e}\")\n",
    "   \n",
    "    # Find cvind.mat file\n",
    "    cvind_files = []\n",
    "    for root, dirs, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "            if file == 'cvind.mat':\n",
    "                cvind_files.append(os.path.join(root, file))\n",
    "   \n",
    "    if not cvind_files:\n",
    "        raise ValueError(\"Could not find cvind.mat file\")\n",
    "   \n",
    "    cvind_path = cvind_files[0]\n",
    "    print(f\"Found cvind.mat at: {cvind_path}\")\n",
    "   \n",
    "    # Load fold indices\n",
    "    with h5py.File(cvind_path, 'r') as f:\n",
    "        idx = np.array(f['cvind']).astype(np.int16).squeeze()\n",
    "   \n",
    "    return img, np.array(lbl), idx\n",
    "\n",
    "# Custom Dataset\n",
    "class BrainTumorDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "   \n",
    "    def __getitem__(self, idx):\n",
    "        # Convert grayscale to RGB by repeating channel\n",
    "        image = self.images[idx]\n",
    "        image = np.repeat(image.reshape(224, 224, 1), 3, axis=2)\n",
    "        label = self.labels[idx] - 1  # Convert to 0-indexed\n",
    "       \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = torch.from_numpy(image.transpose(2, 0, 1)).float()\n",
    "           \n",
    "        return image, label\n",
    "\n",
    "# Define transforms for training and validation with more aggressive augmentation\n",
    "def get_transforms():\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.RandomRotation(30),  # Increased from 15 to 30\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),  # Added scale\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Added color jitter\n",
    "        transforms.RandomPerspective(distortion_scale=0.2, p=0.5),  # Added perspective transform\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        transforms.RandomErasing(p=0.2)  # Added random erasing\n",
    "    ])\n",
    "   \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "   \n",
    "    return train_transform, val_transform\n",
    "\n",
    "# Get train and test splits\n",
    "def get_train_test_data(images, labels, fold_indices, test_fold):\n",
    "    train_mask = fold_indices != test_fold\n",
    "    test_mask = fold_indices == test_fold\n",
    "   \n",
    "    train_images = images[train_mask]\n",
    "    train_labels = labels[train_mask]\n",
    "    test_images = images[test_mask]\n",
    "    test_labels = labels[test_mask]\n",
    "   \n",
    "    return (train_images, train_labels), (test_images, test_labels)\n",
    "\n",
    "# MixUp augmentation\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    '''Compute the mixup data. Return mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "# Squeeze and Excitation Block\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "# CBAM: Convolutional Block Attention Module\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "       \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels // reduction_ratio, 1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels // reduction_ratio, in_channels, 1, bias=False)\n",
    "        )\n",
    "       \n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        out = avg_out + max_out\n",
    "        return torch.sigmoid(out)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n",
    "        padding = 3 if kernel_size == 7 else 1\n",
    "       \n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        out = torch.cat([avg_out, max_out], dim=1)\n",
    "        out = self.conv(out)\n",
    "        return torch.sigmoid(out)\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_ratio=16, kernel_size=7):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channel_attention = ChannelAttention(in_channels, reduction_ratio)\n",
    "        self.spatial_attention = SpatialAttention(kernel_size)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        x = x * self.channel_attention(x)\n",
    "        x = x * self.spatial_attention(x)\n",
    "        return x\n",
    "\n",
    "# Self-Attention Block\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.query = nn.Conv2d(in_channels, in_channels//8, kernel_size=1)\n",
    "        self.key = nn.Conv2d(in_channels, in_channels//8, kernel_size=1)\n",
    "        self.value = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        batch_size, C, width, height = x.size()\n",
    "       \n",
    "        # Reshape for matrix multiplication\n",
    "        proj_query = self.query(x).view(batch_size, -1, width*height).permute(0, 2, 1)  # B X (W*H) X C\n",
    "        proj_key = self.key(x).view(batch_size, -1, width*height)  # B X C X (W*H)\n",
    "       \n",
    "        # Calculate attention map\n",
    "        attention = torch.bmm(proj_query, proj_key)  # B X (W*H) X (W*H)\n",
    "        attention = self.softmax(attention)\n",
    "       \n",
    "        # Apply attention to values\n",
    "        proj_value = self.value(x).view(batch_size, -1, width*height)  # B X C X (W*H)\n",
    "        out = torch.bmm(proj_value, attention.permute(0, 2, 1))  # B X C X (W*H)\n",
    "        out = out.view(batch_size, C, width, height)  # B X C X W X H\n",
    "       \n",
    "        # Add residual connection with learnable parameter gamma\n",
    "        out = self.gamma * out + x\n",
    "       \n",
    "        return out\n",
    "\n",
    "# Dual Path Block - combines features from multiple paths\n",
    "class DualPathBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(DualPathBlock, self).__init__()\n",
    "       \n",
    "        # First path - standard convolution\n",
    "        self.conv_path = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "       \n",
    "        # Second path - depthwise separable convolution\n",
    "        self.dw_path = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=stride, padding=1, groups=in_channels, bias=False),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "       \n",
    "        # Attention module\n",
    "        self.cbam = CBAM(out_channels)\n",
    "       \n",
    "        # Residual connection if dimensions change\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "   \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "       \n",
    "        # Process through both paths\n",
    "        out1 = self.conv_path(x)\n",
    "        out2 = self.dw_path(x)\n",
    "       \n",
    "        # Combine paths with element-wise addition\n",
    "        out = out1 + out2\n",
    "       \n",
    "        # Apply attention\n",
    "        out = self.cbam(out)\n",
    "       \n",
    "        # Apply residual connection\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "       \n",
    "        return out\n",
    "\n",
    "# Feature Pyramid Network (FPN) module\n",
    "class FPN(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(FPN, self).__init__()\n",
    "        self.lateral_conv = nn.Conv2d(channels, 256, kernel_size=1)\n",
    "        self.output_conv = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        lateral = self.lateral_conv(x)\n",
    "        output = self.output_conv(lateral)\n",
    "        return output\n",
    "\n",
    "# Main model with EfficientNet backbone and attention - Modified to support different variants\n",
    "class EnhancedEfficientNetClassifier(nn.Module):\n",
    "    def __init__(self, model_variant='efficient_basic', num_classes=3, dropout_rate=0.3):\n",
    "        super(EnhancedEfficientNetClassifier, self).__init__()\n",
    "       \n",
    "        # Load pretrained EfficientNet and remove final classifier\n",
    "        # Using B4 instead of B3 for higher capacity\n",
    "        efficient_net = models.efficientnet_b4(weights=\"IMAGENET1K_V1\")\n",
    "        self.features = nn.Sequential(*list(efficient_net.children())[:-1])\n",
    "       \n",
    "        # Get the output feature dimension\n",
    "        feature_dim = efficient_net._modules['classifier'][1].in_features\n",
    "        split_dim = feature_dim // 2\n",
    "       \n",
    "        self.model_variant = model_variant\n",
    "       \n",
    "        if model_variant == 'efficient_basic':\n",
    "            # Basic variant with Self-Attention and SE blocks\n",
    "            self.attention1 = SelfAttention(split_dim)\n",
    "            self.attention2 = SelfAttention(split_dim)\n",
    "            self.se1 = SEBlock(split_dim)\n",
    "            self.se2 = SEBlock(split_dim)\n",
    "           \n",
    "        elif model_variant == 'efficient_cbam':\n",
    "            # Enhanced variant with CBAM\n",
    "            self.cbam1 = CBAM(split_dim)\n",
    "            self.cbam2 = CBAM(split_dim)\n",
    "           \n",
    "        elif model_variant == 'efficient_dual':\n",
    "            # Dual path variant\n",
    "            self.dual_path1 = DualPathBlock(split_dim, split_dim)\n",
    "            self.dual_path2 = DualPathBlock(split_dim, split_dim)\n",
    "           \n",
    "        # FPN modules for multi-scale feature extraction\n",
    "        self.fpn1 = FPN(split_dim)\n",
    "        self.fpn2 = FPN(split_dim)\n",
    "       \n",
    "        # Global pooling\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "       \n",
    "        # Additional features: Global Context Block\n",
    "        self.gcb = nn.Sequential(\n",
    "            nn.Conv2d(512, 64, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(64, 512, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "       \n",
    "        # Fully connected layers with improved regularization\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),  # Increased dropout\n",
    "            nn.Linear(512, 256),  # Added an extra FC layer\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate/2),  # Lower dropout in the last layer\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "   \n",
    "    def forward(self, x):\n",
    "        # Extract features using EfficientNet backbone\n",
    "        features = self.features(x)\n",
    "       \n",
    "        # Split features into two parts\n",
    "        features1, features2 = torch.split(features, features.size(1)//2, dim=1)\n",
    "       \n",
    "        # Apply attention based on model variant\n",
    "        if self.model_variant == 'efficient_basic':\n",
    "            features1 = self.attention1(features1)\n",
    "            features1 = self.se1(features1)\n",
    "           \n",
    "            features2 = self.attention2(features2)\n",
    "            features2 = self.se2(features2)\n",
    "           \n",
    "        elif self.model_variant == 'efficient_cbam':\n",
    "            features1 = self.cbam1(features1)\n",
    "            features2 = self.cbam2(features2)\n",
    "           \n",
    "        elif self.model_variant == 'efficient_dual':\n",
    "            features1 = self.dual_path1(features1)\n",
    "            features2 = self.dual_path2(features2)\n",
    "       \n",
    "        # Apply FPN for multi-scale feature enhancement\n",
    "        features1 = self.fpn1(features1)\n",
    "        features2 = self.fpn2(features2)\n",
    "       \n",
    "        # Concatenate features\n",
    "        combined_features = torch.cat([features1, features2], dim=1)\n",
    "       \n",
    "        # Apply global context\n",
    "        context = self.gcb(combined_features)\n",
    "        combined_features = combined_features * context\n",
    "       \n",
    "        # Global pooling\n",
    "        pooled = self.global_pool(combined_features)\n",
    "        pooled = pooled.view(pooled.size(0), -1)\n",
    "       \n",
    "        # Classification\n",
    "        output = self.classifier(pooled)\n",
    "       \n",
    "        return output\n",
    "\n",
    "# Training function with mixup and label smoothing\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=10, mixup_alpha=0.0):\n",
    "    best_val_acc = 0.0\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "   \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "       \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        total_samples = 0\n",
    "       \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "           \n",
    "            # Apply mixup if alpha > 0\n",
    "            if mixup_alpha > 0:\n",
    "                inputs, labels_a, labels_b, lam = mixup_data(inputs, labels, mixup_alpha)\n",
    "                use_mixup = True\n",
    "            else:\n",
    "                use_mixup = False\n",
    "           \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "           \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "           \n",
    "            # Calculate loss with or without mixup\n",
    "            if use_mixup:\n",
    "                loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)\n",
    "                # For accuracy calculation with mixup, we use the dominant label\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_corrects += (lam * torch.sum(preds == labels_a) +\n",
    "                                   (1 - lam) * torch.sum(preds == labels_b)).float()\n",
    "            else:\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "           \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "           \n",
    "            # Statistics\n",
    "            batch_size = inputs.size(0)\n",
    "            running_loss += loss.item() * batch_size\n",
    "            total_samples += batch_size\n",
    "       \n",
    "        # Step scheduler if it's not OneCycleLR (which steps per batch)\n",
    "        if CONFIG['scheduler'] != 'onecycle':\n",
    "            scheduler.step()\n",
    "       \n",
    "        epoch_loss = running_loss / total_samples\n",
    "        epoch_acc = running_corrects.double() / total_samples\n",
    "       \n",
    "        history['train_loss'].append(epoch_loss)\n",
    "        history['train_acc'].append(epoch_acc.cpu().numpy())\n",
    "       \n",
    "        print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "       \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_running_corrects = 0\n",
    "        val_total_samples = 0\n",
    "       \n",
    "        # No gradient calculation needed for validation\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "               \n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "               \n",
    "                # Statistics\n",
    "                batch_size = inputs.size(0)\n",
    "                val_running_loss += loss.item() * batch_size\n",
    "                val_running_corrects += torch.sum(preds == labels.data)\n",
    "                val_total_samples += batch_size\n",
    "       \n",
    "        val_epoch_loss = val_running_loss / val_total_samples\n",
    "        val_epoch_acc = val_running_corrects.double() / val_total_samples\n",
    "       \n",
    "        history['val_loss'].append(val_epoch_loss)\n",
    "        history['val_acc'].append(val_epoch_acc.cpu().numpy())\n",
    "       \n",
    "        print(f'Val Loss: {val_epoch_loss:.4f} Acc: {val_epoch_acc:.4f}')\n",
    "       \n",
    "        # Save best model\n",
    "        if val_epoch_acc > best_val_acc:\n",
    "            best_val_acc = val_epoch_acc\n",
    "            torch.save(model.state_dict(), f'best_{CONFIG[\"model_variant\"]}_model.pth')\n",
    "            print(f'New best model saved with accuracy: {val_epoch_acc:.4f}')\n",
    "       \n",
    "        print()\n",
    "   \n",
    "    # Load best model weights\n",
    "    model.load_state_dict(torch.load(f'best_{CONFIG[\"model_variant\"]}_model.pth'))\n",
    "    return model, history\n",
    "\n",
    "# Evaluation function with advanced metrics\n",
    "def evaluate_model(model, test_loader, num_classes=3):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "   \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "           \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "   \n",
    "    # Convert to numpy arrays\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probs = np.array(all_probs)\n",
    "   \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "   \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "   \n",
    "    # Classification Report\n",
    "    report = classification_report(all_labels, all_preds)\n",
    "   \n",
    "    # ROC Curve and AUC\n",
    "    # Binarize the labels for ROC calculation\n",
    "    labels_bin = label_binarize(all_labels, classes=range(num_classes))\n",
    "   \n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(num_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(labels_bin[:, i], all_probs[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "   \n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(labels_bin.ravel(), all_probs.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "   \n",
    "    # Compute macro-average ROC curve and ROC area\n",
    "    # First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(num_classes)]))\n",
    "   \n",
    "    # Then interpolate all ROC curves at these points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(num_classes):\n",
    "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "   \n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= num_classes\n",
    "   \n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "   \n",
    "    # Plot ROC Curves\n",
    "    plt.figure(figsize=(12, 8))\n",
    "   \n",
    "    # Plot micro-average ROC curve\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "             label=f'Micro-average ROC curve (area = {roc_auc[\"micro\"]:.2f})',\n",
    "             color='deeppink', linestyle=':', linewidth=4)\n",
    "   \n",
    "    # Plot macro-average ROC curve\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "             label=f'Macro-average ROC curve (area = {roc_auc[\"macro\"]:.2f})',\n",
    "             color='navy', linestyle=':', linewidth=4)\n",
    "   \n",
    "    # Plot ROC curves for all classes\n",
    "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "    class_names = ['Meningioma', 'Glioma', 'Pituitary']\n",
    "   \n",
    "    for i, color, name in zip(range(num_classes), colors, class_names):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                 label=f'ROC curve of {name} (area = {roc_auc[i]:.2f})')\n",
    "   \n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - {CONFIG[\"model_variant\"]}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(f'{CONFIG[\"model_variant\"]}_roc_curve.png')\n",
    "    plt.close()\n",
    "   \n",
    "    # Plot Confusion Matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(f'Confusion Matrix - {CONFIG[\"model_variant\"]}')\n",
    "    plt.colorbar()\n",
    "   \n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "   \n",
    "    # Add text annotations to the confusion matrix\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "   \n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{CONFIG[\"model_variant\"]}_confusion_matrix.png')\n",
    "    plt.close()\n",
    "   \n",
    "    # Return metrics and predictions\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'confusion_matrix': cm,\n",
    "        'classification_report': report,\n",
    "        'roc_auc': roc_auc,\n",
    "        'predictions': all_preds,\n",
    "        'labels': all_labels,\n",
    "        'probabilities': all_probs\n",
    "    }\n",
    "\n",
    "# Function to test with a random image\n",
    "def test_random_image(model, images, labels, transform=None):\n",
    "    \"\"\"\n",
    "    Test the model with a random image from the dataset\n",
    "   \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        images: Image data\n",
    "        labels: Labels\n",
    "        transform: Image transform function\n",
    "       \n",
    "    Returns:\n",
    "        prediction: The model's prediction\n",
    "    \"\"\"\n",
    "    # Choose a random image\n",
    "    idx = random.randint(0, len(images) - 1)\n",
    "    img = images[idx]\n",
    "    true_label = labels[idx] - 1  # Convert totrue_label = labels[idx] - 1  # Convert to 0-indexed\n",
    "   \n",
    "    # Preprocess the image\n",
    "    img = np.repeat(img.reshape(224, 224, 1), 3, axis=2)\n",
    "   \n",
    "    # Apply transform if provided\n",
    "    if transform:\n",
    "        img_tensor = transform(img).unsqueeze(0).to(device)  # Add batch dimension\n",
    "    else:\n",
    "        img_tensor = torch.from_numpy(img.transpose(2, 0, 1)).float().unsqueeze(0).to(device)\n",
    "   \n",
    "    # Get model prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        probs = F.softmax(output, dim=1)\n",
    "        _, pred = torch.max(output, 1)\n",
    "   \n",
    "    # Display the image and prediction\n",
    "    class_names = ['Meningioma', 'Glioma', 'Pituitary']\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f'True: {class_names[true_label]}, Pred: {class_names[pred.item()]}\\nConfidence: {probs[0][pred.item()]:.4f}')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f'{CONFIG[\"model_variant\"]}_random_test.png')\n",
    "    plt.close()\n",
    "   \n",
    "    print(f\"Random image test - True: {class_names[true_label]}, Predicted: {class_names[pred.item()]}\")\n",
    "    print(f\"Confidence scores: {probs[0].cpu().numpy()}\")\n",
    "   \n",
    "    return {\n",
    "        'image_idx': idx,\n",
    "        'true_label': true_label,\n",
    "        'predicted_label': pred.item(),\n",
    "        'confidence': probs[0][pred.item()].item(),\n",
    "        'all_probs': probs[0].cpu().numpy()\n",
    "    }\n",
    "\n",
    "# Main execution function\n",
    "def run_experiment(fold_index):\n",
    "    print(f\"\\n{'='*20} RUNNING FOLD {fold_index} {'='*20}\\n\")\n",
    "   \n",
    "    # Load data\n",
    "    images, labels, fold_indices = load_data()\n",
    "   \n",
    "    # Get train and test data for this fold\n",
    "    (train_images, train_labels), (test_images, test_labels) = get_train_test_data(\n",
    "        images, labels, fold_indices, fold_index)\n",
    "   \n",
    "    # Create datasets with transforms\n",
    "    train_transform, val_transform = get_transforms()\n",
    "   \n",
    "    train_dataset = BrainTumorDataset(train_images, train_labels, transform=train_transform)\n",
    "    test_dataset = BrainTumorDataset(test_images, test_labels, transform=val_transform)\n",
    "   \n",
    "    # Create data loaders with larger batch size\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True  # Add pin_memory for faster data transfer to GPU\n",
    "    )\n",
    "   \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "   \n",
    "    # Initialize model based on selected variant\n",
    "    model = EnhancedEfficientNetClassifier(\n",
    "        model_variant=CONFIG['model_variant'],\n",
    "        num_classes=CONFIG['num_classes'],\n",
    "        dropout_rate=CONFIG['dropout_rate']\n",
    "    )\n",
    "    model = model.to(device)\n",
    "   \n",
    "    # Loss function with label smoothing\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=CONFIG['label_smoothing'])\n",
    "   \n",
    "    # Optimizer with weight decay\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=CONFIG['base_lr'],\n",
    "        weight_decay=CONFIG['weight_decay']\n",
    "    )\n",
    "   \n",
    "    # Set scheduler based on configuration\n",
    "    if CONFIG['scheduler'] == 'cosine':\n",
    "        scheduler = CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=CONFIG['num_epochs'],\n",
    "            eta_min=CONFIG['base_lr'] / 100\n",
    "        )\n",
    "    elif CONFIG['scheduler'] == 'onecycle':\n",
    "        # OneCycle learning rate scheduler\n",
    "        scheduler = OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=CONFIG['base_lr'] * 10,  # Peak LR is 10x the base LR\n",
    "            steps_per_epoch=len(train_loader),\n",
    "            epochs=CONFIG['num_epochs'],\n",
    "            pct_start=0.3,  # Spend 30% of time increasing LR\n",
    "            div_factor=25.0,  # Initial LR = max_lr/25\n",
    "            final_div_factor=10000.0  # Final LR = initial_lr/10000\n",
    "        )\n",
    "   \n",
    "    # Train model with specified epochs\n",
    "    start_time = time.time()\n",
    "    model, history = train_model(\n",
    "        model,\n",
    "        train_loader,\n",
    "        test_loader,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        num_epochs=CONFIG['num_epochs'],\n",
    "        mixup_alpha=CONFIG['mixup_alpha']\n",
    "    )\n",
    "    end_time = time.time()\n",
    "   \n",
    "    # Evaluate model with advanced metrics\n",
    "    metrics = evaluate_model(model, test_loader, num_classes=CONFIG['num_classes'])\n",
    "    accuracy = metrics['accuracy']\n",
    "   \n",
    "    print(f\"Fold {fold_index} accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(metrics['classification_report'])\n",
    "   \n",
    "    # Get ROC AUC scores\n",
    "    print(\"\\nROC AUC Scores:\")\n",
    "    for i in range(CONFIG['num_classes']):\n",
    "        print(f\"Class {i}: {metrics['roc_auc'][i]:.4f}\")\n",
    "    print(f\"Micro-average: {metrics['roc_auc']['micro']:.4f}\")\n",
    "    print(f\"Macro-average: {metrics['roc_auc']['macro']:.4f}\")\n",
    "   \n",
    "    # Plot loss curve\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title(f'Loss Curves for Fold {fold_index} - {CONFIG[\"model_variant\"]}')\n",
    "    plt.savefig(f'{CONFIG[\"model_variant\"]}_loss_curve_fold_{fold_index}.png')\n",
    "    plt.close()\n",
    "   \n",
    "    # Plot accuracy curve\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history['train_acc'], label='Train Acc')\n",
    "    plt.plot(history['val_acc'], label='Val Acc')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title(f'Accuracy Curves for Fold {fold_index} - {CONFIG[\"model_variant\"]}')\n",
    "    plt.savefig(f'{CONFIG[\"model_variant\"]}_acc_curve_fold_{fold_index}.png')\n",
    "    plt.close()\n",
    "   \n",
    "    # Test with a random image\n",
    "    random_test_results = test_random_image(model, images, labels, transform=val_transform)\n",
    "   \n",
    "    # Save model and results\n",
    "    torch.save(model.state_dict(), f'{CONFIG[\"model_variant\"]}_model_fold_{fold_index}.pth')\n",
    "    np.save(f'{CONFIG[\"model_variant\"]}_results_fold_{fold_index}.npy', metrics)\n",
    "   \n",
    "    return metrics\n",
    "\n",
    "# Run for all folds\n",
    "if __name__ == \"__main__\":\n",
    "    results_all = {}\n",
    "   \n",
    "    # Run for all 5 folds\n",
    "    for fold in range(1, 6):\n",
    "        try:\n",
    "            metrics = run_experiment(fold)\n",
    "            results_all[fold] = metrics\n",
    "        except Exception as e:\n",
    "            print(f\"Error in fold {fold}: {e}\")\n",
    "   \n",
    "    # Calculate and print average accuracy across all folds\n",
    "    accuracies = [results_all[fold]['accuracy'] for fold in results_all if fold in results_all]\n",
    "    if accuracies:\n",
    "        avg_accuracy = np.mean(accuracies)\n",
    "        print(f\"\\nAverage accuracy across all folds: {avg_accuracy:.4f}\")\n",
    "       \n",
    "        # Calculate average AUC across all folds\n",
    "        avg_auc_micro = np.mean([results_all[fold]['roc_auc']['micro'] for fold in results_all if fold in results_all])\n",
    "        avg_auc_macro = np.mean([results_all[fold]['roc_auc']['macro'] for fold in results_all if fold in results_all])\n",
    "        print(f\"Average micro-average AUC: {avg_auc_micro:.4f}\")\n",
    "        print(f\"Average macro-average AUC: {avg_auc_macro:.4f}\")\n",
    "       \n",
    "        # Model and configuration summary\n",
    "        print(\"\\nModel Configuration Summary:\")\n",
    "        print(f\"  Model variant: {CONFIG['model_variant']}\")\n",
    "        print(f\"  Batch size: {CONFIG['batch_size']}\")\n",
    "        print(f\"  Epochs: {CONFIG['num_epochs']}\")\n",
    "        print(f\"  Learning rate: {CONFIG['base_lr']}\")\n",
    "        print(f\"  Weight decay: {CONFIG['weight_decay']}\")\n",
    "        print(f\"  Scheduler: {CONFIG['scheduler']}\")\n",
    "        print(f\"  MixUp alpha: {CONFIG['mixup_alpha']}\")\n",
    "        print(f\"  Label smoothing: {CONFIG['label_smoothing']}\")\n",
    "        print(f\"  Dropout rate: {CONFIG['dropout_rate']}\")\n",
    "       \n",
    "    # Visualize learning curves across all folds\n",
    "    if results_all:\n",
    "        # Plot average accuracy across folds\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for fold in results_all:\n",
    "            plt.plot(results_all[fold]['val_acc'], label=f'Fold {fold}')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Validation Accuracy')\n",
    "        plt.title(f'Validation Accuracy Across Folds - {CONFIG[\"model_variant\"]}')\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.savefig(f'{CONFIG[\"model_variant\"]}_all_folds_accuracy.png')\n",
    "        plt.close()\n",
    "       \n",
    "        # Generate final summary visualization of class-wise metrics\n",
    "        class_names = ['Meningioma', 'Glioma', 'Pituitary']\n",
    "        class_aucs = []\n",
    "        for i in range(CONFIG['num_classes']):\n",
    "            class_auc = np.mean([results_all[fold]['roc_auc'][i] for fold in results_all if fold in results_all])\n",
    "            class_aucs.append(class_auc)\n",
    "       \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(class_names, class_aucs, color=['skyblue', 'lightgreen', 'salmon'])\n",
    "        plt.ylabel('Average AUC')\n",
    "        plt.title(f'Average AUC by Class - {CONFIG[\"model_variant\"]}')\n",
    "        plt.ylim(0.8, 1.0)  # Adjust as needed\n",
    "        for i, v in enumerate(class_aucs):\n",
    "            plt.text(i, v + 0.01, f\"{v:.4f}\", ha='center')\n",
    "        plt.savefig(f'{CONFIG[\"model_variant\"]}_class_aucs.png')\n",
    "        plt.close()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2020131,
     "sourceId": 3347069,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2777.546427,
   "end_time": "2025-05-06T22:18:57.004284",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-06T21:32:39.457857",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
